{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7c7e900e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e2ea4920",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['marketplace', 'customer_id', 'review_id', 'product_id',\n",
       "       'product_parent', 'product_title', 'product_category', 'star_rating',\n",
       "       'helpful_votes', 'total_votes', 'vine', 'verified_purchase',\n",
       "       'review_headline', 'review_body', 'review_date'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(\"amazon_reviews_us_Electronics_v1_00.tsv\", delimiter = '\\t',nrows=999999, on_bad_lines = 'skip')\n",
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "289b9ff7",
   "metadata": {},
   "outputs": [],
   "source": [
    "class RatingDataset(Dataset):\n",
    "    def __init__(self, users, items, ratings):\n",
    "        self.users = torch.tensor(users, dtype=torch.long)\n",
    "        self.items = torch.tensor(items, dtype=torch.long)\n",
    "        self.ratings = torch.tensor(ratings, dtype=torch.float)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.users)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return self.users[idx], self.items[idx], self.ratings[idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20887986",
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_data_MF(file_path):\n",
    "    df = pd.read_csv(file_path, delimiter = '\\t',nrows=999999, on_bad_lines = 'skip')\n",
    "    df = df[['customer_id', 'product_id', 'star_rating']]\n",
    "    \n",
    "    #filter the dataframe to only include customers with more than 5 records and products with more than 6 records\n",
    "    \n",
    "    customers = df['customer_id'].value_counts()\n",
    "    products = df['product_id'].value_counts()\n",
    "    \n",
    "    selected_customers = customers[customers >= 5].index\n",
    "    selected_products = products[products >= 10].index\n",
    "    \n",
    "    filtered_df = df[df['product_id'].isin(selected_products)]\n",
    "    filtered_df = filtered_df[filtered_df['customer_id'].isin(selected_customers)]\n",
    "    \n",
    "    customers = filtered_df['customer_id'].value_counts()\n",
    "    products = filtered_df['product_id'].value_counts()\n",
    "    \n",
    "    customer_idx = pd.DataFrame({'customer_id': customers.index, 'user': np.arange(customers.shape[0])})\n",
    "    product_idx = pd.DataFrame({'product_id': products.index, 'item': np.arange(products.shape[0])})\n",
    "    \n",
    "    filtered_df = filtered_df.merge(customer_idx).merge(product_idx)\n",
    "    \n",
    "    train_df, test_df = train_test_split(filtered_df, test_size = 0.2, random_state = 0)\n",
    "    \n",
    "    # PyTorch data loaders\n",
    "    train_dataset = RatingDataset(train_df['user'].values, train_df['item'].values, train_df['star_rating'].values)\n",
    "    test_dataset = RatingDataset(test_df['user'].values, test_df['item'].values, test_df['star_rating'].values)\n",
    "\n",
    "    train_loader = DataLoader(train_dataset, shuffle=True, batch_size=batch_size, num_workers=4, drop_last=True)\n",
    "    test_loader = DataLoader(test_dataset, shuffle=True, batch_size=batch_size, num_workers=4, drop_last=True)\n",
    "\n",
    "    return train_iter, test_iter, customer_idx, product_idx \n",
    "    \n",
    "    \n",
    "\n",
    "    \n",
    "    \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c28fe443",
   "metadata": {},
   "outputs": [],
   "source": [
    "#todo: prepare data for embedding based sim\n",
    "class prepare_data_twotower(Dataset):\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37a22f6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#matrix factorization colaborative filtering\n",
    "class MFModel(nn.Module):\n",
    "    def __init__(self, max_users, max_items, emb_dim, dropout_rate=0.5):\n",
    "        super(MFModel, self).__init__()\n",
    "        self.max_users = max_users\n",
    "        self.max_items = max_items\n",
    "        self.dropout_rate = dropout_rate\n",
    "        self.emb_dim = emb_dim\n",
    "\n",
    "        self.user_embeddings = nn.Embedding(max_users, emb_dim)\n",
    "        self.item_embeddings = nn.Embedding(max_items, emb_dim)\n",
    "\n",
    "        self.dropout_user = nn.Dropout(dropout_rate)\n",
    "        self.dropout_item = nn.Dropout(dropout_rate)\n",
    "\n",
    "        self.dense_user = nn.Linear(emb_dim, emb_dim)\n",
    "        self.dense_item = nn.Linear(emb_dim, emb_dim)\n",
    "\n",
    "    def forward(self, users, items):\n",
    "        a = self.user_embeddings(users)\n",
    "        a = self.dense_user(a)\n",
    "        a = nn.functional.relu(a)\n",
    "        a = self.dropout_user(a)\n",
    "\n",
    "        b = self.item_embeddings(items)\n",
    "        b = self.dense_item(b)\n",
    "        b = nn.functional.relu(b)\n",
    "        b = self.dropout_item(b)\n",
    "\n",
    "        predictions = a * b\n",
    "        predictions = torch.sum(predictions, dim=1)\n",
    "\n",
    "        return predictions\n",
    "\n",
    "\n",
    "\n",
    "            \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56f1a656",
   "metadata": {},
   "outputs": [],
   "source": [
    "#two tower nn - embedding-based sim \n",
    "class TwoTowerModel(nn.Module):\n",
    "    def __init__(self, num_media_items, num_users, embedding_size):\n",
    "        super(TwoTowerModel, self).__init__()\n",
    "\n",
    "        # Embedding layers for item and user categorical features\n",
    "        self.item_sparse_embedding = nn.Embedding(num_embeddings=num_items, embedding_dim=embedding_size)\n",
    "        self.user_sparse_embedding = nn.Embedding(num_embeddings=num_users, embedding_dim=embedding_size)\n",
    "\n",
    "        # Fully connected layers for item and user dense features\n",
    "        self.item_dense_layers = nn.Sequential(\n",
    "            nn.Linear(in_features=3, out_features=10),\n",
    "            nn.ReLU()\n",
    "        )\n",
    "\n",
    "        self.user_dense_layers = nn.Sequential(\n",
    "            nn.Linear(in_features=2, out_features=10),\n",
    "            nn.ReLU()\n",
    "        )\n",
    "\n",
    "        # Output layer\n",
    "        self.output_layer = nn.Linear(in_features=20, out_features=1)  \n",
    "\n",
    "    def forward(self, item_sparse, item_dense, user_sparse, user_dense):\n",
    "        # Embed sparse features\n",
    "        item_sparse_embedded = self.item_sparse_embedding(item_sparse)\n",
    "        user_sparse_embedded = self.user_sparse_embedding(user_sparse)\n",
    "\n",
    "        # Apply dense layers to dense features\n",
    "        item_dense_processed = self.item_dense_layers(item_dense)\n",
    "        user_dense_processed = self.user_dense_layers(user_dense)\n",
    "\n",
    "        # Concatenate embedded and processed features\n",
    "        item_combined_features = torch.cat([item_sparse_embedded, item_dense_processed], dim=1)\n",
    "        user_combined_features = torch.cat([user_sparse_embedded, user_dense_processed], dim=1)\n",
    "\n",
    "        # Apply the output layer\n",
    "        item_output = self.output_layer(item_combined_features)\n",
    "        user_output = self.output_layer(user_combined_features)\n",
    "\n",
    "        return item_output, user_output\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7034e34",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, train_loader, test_loader, file_path, n_epochs):\n",
    "    model.to(device)\n",
    "    for epoch in range(n_epochs):\n",
    "        device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "        \n",
    "        mode.train()\n",
    "        criterion = nn.MSELoss()\n",
    "        \n",
    "        for user, item, rating in train_loader:\n",
    "            #transfer data to gpu\n",
    "            users, items, ratings = users.to(device), items.to(device), ratings.to(device)\n",
    "            \n",
    "            #forward pass\n",
    "            outputs = model(users, items)\n",
    "            loss = criterion(outputs, ratings)\n",
    "            \n",
    "            #backward pass\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            \n",
    "            #update parameters\n",
    "            optimizer.step()\n",
    "            \n",
    "        #evaluate \n",
    "        \n",
    "        model.eval()\n",
    "        train_loss = evaluate(model, train_loader)\n",
    "        test_loss = evaluate(model, test_loader)\n",
    "        print(f\"Epoch {epoch + 1}/{n_epochs}, Train MSE: {train_loss}, Test MSE: {test_loss}\")\n",
    "        \n",
    "        return model\n",
    "\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50e95f4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(model, data_loader):\n",
    "    model.eval()\n",
    "    \n",
    "    criterion = nn.MSELoss()\n",
    "    loss = 0\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for users, items, ratings in data_loader:\n",
    "            users, items, ratings = users.to(device), items.to(device), ratings.to(device)\n",
    "            y_pred = model(users, items)\n",
    "            loss += criterion(y_pred, ratings).item()\n",
    "            \n",
    "            \n",
    "    return loss/len(data_loader)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d1faa42",
   "metadata": {},
   "outputs": [],
   "source": [
    "def save(model, model_dir, customer_idx, product_idx):\n",
    "    torch.save(model.state_dict(), os.path.join(model_dir, 'model.pth'))\n",
    "    customer_idx.to_csv(os.path.join(model_dir, 'customer_index.csv'), index=False)\n",
    "    product_idx.to_csv(os.path.join(model_dir, 'product_index.csv'), index=False)\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58b729fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_model(model_dir):\n",
    "    model = MFModel(max_users=100, max_items=100, emb_dim=64, dropout_rate=0.5)\n",
    "    model.load_state_dict(torch.load(os.path.join(model_dir, 'model.pth')))\n",
    "    customer_index = pd.read_csv(os.path.join(model_dir, 'customer_index.csv'))\n",
    "    product_index = pd.read_csv(os.path.join(model_dir, 'product_index.csv'))\n",
    "    return model, customer_index, product_index\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6b5ce08",
   "metadata": {},
   "outputs": [],
   "source": [
    "#inference\n",
    "# Transform function\n",
    "def transform_fn(model, data, input_content_type, output_content_type):\n",
    "    model.eval()\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    parsed = json.loads(data)\n",
    "    \n",
    "    users = pd.DataFrame({'customer_id': parsed['customer_id']}).merge(model[1], how='left')['user'].values\n",
    "    items = pd.DataFrame({'product_id': parsed['product_id']}).merge(model[2], how='left')['item'].values\n",
    "\n",
    "    inputs = torch.tensor([users, items], dtype=torch.long).to(device)\n",
    "    with torch.no_grad():\n",
    "        outputs = model(*inputs)\n",
    "    \n",
    "    response_body = json.dumps(outputs.cpu().numpy().tolist())\n",
    "    return response_body, output_content_type\n",
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
